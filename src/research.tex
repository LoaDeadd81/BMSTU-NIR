\chapter[Исследование существующих алгоритмов обучения\\ранжированию]{Исследование существующих алгоритмов \\обучения ранжированию}

\section{Классификация алгоритмов}

Существующие алгоритмы обучения ранжированию делятся на три группы по подходу к обучению~\cite{ML_for_SE}: поточечный, попарный и списочный.

Поточечный подход --- частный случай задачи регрессии или классификации, если множество оценок конечно, в ходе ее решения возможно использовать метод градиентного спуска, опорных векторов и т.~д непосредственно. На практике этот подход дает не очень качественный результат, так как каждый документ ранжируется независимо от других. В качестве примеров для обучения используют пары <<признаки~---~значение релевантности>>. Данная задача может быть аппроксимирована задачей регрессии --- учитывая единственную пару <<запрос~---~документ>>, спрогнозировать ее оценку. Точечный подход направлен на изучение функции, предсказывающей реальное значение или порядковый номер документа, используя функцию потерь. Окончательное ранжирование достигается путем простой сортировки списка результатов по оценке документа, выданной обученной моделью~\cite{LR_BOOK}.

При попарном подходе обучение ранжированию сводится к построению бинарного классификатора, которому на вход поступают два документа, соответствующих одному и тому же запросу, и требуется определить, какой релевантнее. Классификатор должен принимать два документа в качестве входных данных, его цель состоит в том, чтобы минимизировать функцию потерь. Недостатком также является невозвомжность учета всех документов запроса. Целью обучения таких алгоритмов является минимизация ошибок в классификации пар документов, а не минимизация ошибок в ранжировании документов, поэтому процесс обучения требует больших вычислительных затрат,а количество сгенерированных пар документов в значительной степени варьируется от запроса к запросу, что приводит к обучению модели, ориентированной на запросы с большим количеством пар. При ранжировании алгоритмы получают пару документов на вход и определяет их порядок относительно друг друга~\cite{LR_BOOK}.

Списочный подход заключается в построении модели, на вход которой поступают сразу все документы, соответствующие запросу, а на выходе получается их перестановка. Подгонка параметров модели осуществляется для прямой максимизации одной метрик ранжирования. Но это часто затруднительно, так как метрики ранжирования обычно не непрерывны и недифференцируемы относительно параметров ранжирующей модели, поэтому прибегают к максимизации неких их приближений или нижних оценок. С точки зрения поставленной ранжирования, списочные методы  решают исходную постановку задачи. Являются одними из самых лучших методов на данный момент, но  сложны в разработке и подборе обучающих наборов данных. При таком подходе алгоритмы непосредственно просматривают весь список документов и подбирают для него оптимальный порядок~\cite{LR_BOOK}.

\section{Алгоритмы обучения ранжированию}

В данном разделе будут рассмотрены несколько популярных алгоритмов из каждой категории: Linear Regression (поточечный), Ranking SVM (попарный), LambdaRank(попарный), ListNet(списочный). 

Перед описанием алгоритмов стоит введём следующие обозначения:
\begin{itemize}[label=---]
	\item $q_{i}$ --- $i$-ый поисковый запрос;
	\item $D_{i}$ --- список всех документов, которые ассоциированы с $q_{i}$ запросом;
	\item $d_{i,j}$ --- $j$-ый документ из списка $D_{i}$;
	\item $\pi_{i}$ --- отсортированный список $D_{i}$;
	\item $y_{i,j}$ --- метка, показывающая на сколько документ $d_{i,j}$ релевантен к запросу $q_{i}$;
	\item $y_{i}$ --- вектор меток $y_{i,j}$.
\end{itemize}

На этапе ранжирования методы имеют схожий алгоритм. Для каждого документа $d_{i,j}$ вычисляется рейтинг релевантности, который зависит от вектора признаков документа $x_{i,j}$ и параметров метода ранжирования $\omega$. Затем рейтинги сортируются по убыванию и получается ранжированный список документов.  

При ранжировании признаки формируются не только на основании документа или запроса по отдельности, но и как функция от поискового запроса и документа в совокупности. Такие признаки способны информативно отражают степень релевантности документа запросу, так как лучше отображают связь запроса и документа.
Зачастую используются следующие признаки:
\begin{itemize}[label=---]
	\item текстовые --- описывают количество и место слов встречающихся в документе и запросе. Используются меры, такие как TF-IDF, используемая для оценки важности слов в контексте документа, BM 25 и различные языковые модели;
	\item ссылочные --- описывают количество гиперссылок на документ на других сайтах и сколько внутри самого документа полезных ссылок, удовлетворяющих запросу. Мера PageRank назначает каждому документу некоторое численное значение, измеряющее его «важность» или «авторитетность» среди остальных документов основываясь на информации о гиперссылках на эту страницу.   HITS позволяет находить страницы, соответствующие запросу пользователя, на основе информации, заложенной в ссылках, находящихся в документе. Идея основана на предположении, что гиперссылки кодируют значительное количество скрытых сайтов соответствующий запросу пользователя. Рекурсивно просматривая ссылки, находящиеся на странице, алгоритм оценивает их содержание и в соответствии с этим переоценивает страницу, содержащую эти ссылки;
	\item кликовые --- описывают количество кликов пользователей на документ в поисковой выдаче. Учитывается как общее количество кликов, так и по какому-то определённому запросу.
\end{itemize}

\subsection{Linear Regression}

 Метод обучения на основе регрессии используется для решения задачи оптимизации метрик DCG~\cite{LR}. Пусть $F$ --- функциональное пространство, содержащее функции $X \times S \to F$, где $X$ --- множество векторов представления документов, $S$ --- множества всех конечных подмножеств $X$. Произвольно созданы множества $S_{1}, \dots, S{n}$, где $S_{i} = \{x_{i,1}, \dots, x_{i,m}\}$, с соответствующими оценками $\{y_{i,j}\}_{j} = \{y_{i,1}, \dots, y_{i,m}\}$. Тогда для решения проблемы ранжирования можно использовать простой подход, основанный на регрессии:
\begin{equation}
	\label{eq:LR1}
	\hat{f}=\arg \min _{f \in \mathcal{F}} \frac{1}{n} \sum_{i=1}^n[\sum_{j=1}^m(f(x_{i, j}, S_i)-y_{i, j})^2].
\end{equation}

Регрессия --- задача прогнозирования метки по набору признаков объектов в общем случае. Метка здесь может принимать любое значение. Алгоритм моделирует зависимость меток от признаков, чтобы определить закономерности изменения меток в зависимости характеристик объекта. При обучении алгоритму на вход подаются примеры с известными метками. Результатом работы является функция, способная прогнозировать значение метки для новых данных. 

Для возможности предсказания меток в регрессии гиперплоскость проводиться так, чтобы оказаться как можно ближе к обучающим примерам~\cite{ML_no_wors}. Для этого требуется минимизировать целевую функцию~(\ref{eq:LR1}). Выражение \\$(f(x_{i, j}, S_i)-y_{i, j})^2$ называют функцией потерь, в данном случае используется квадратичная функция потерь. Она определяет величину штрафа за неправильную классификацию. В этом алгоритме функция стоимости определена как средняя потеря. Минимизировав целевую функцию получим оптимальные параметры модели, для предсказания меток.

Однако метод прямой регрессии не подходит для крупномасштабных задач ранжирования, таких как веб-поиск, для которых требуется ранжировать множество элементов, хорошим результатом работы такого алгоритма будет выбор страниц с самым высоким рейтингом. Данный метод уделяет равное внимание релевантным и нерелевантным страницам. На самом деле, следует уделять больше внимания страницам с самым высоким рейтингом. Оценка страниц с низкой релевантностью не нуждается в большой точности, до тех пор, пока не происходит новая оценка их релевантности для того, чтобы эти страницы отображались на верхних позициях в поиске. С учётом этих рассуждений стоит изменить формулу~(\ref{eq:LR1}) следующим образом:
	
{\begin{equation}
			\label{eq:LR2}
		\hat{f}=\arg \min _{f \in \mathcal{F}}
		\frac{1}{n} \sum_{i=1}^n L(f, S_i,\{y_{i, j}\}_j),
\end{equation}}
где для $S = \{x_{1}, \dots, x_{m}\}$, с соответствующим $\{y_{j}\}_{j}$, имеем функцию потерь:
\[
\begin{aligned}
	& L(f, S,\{y_j\}_j) \\
	= & \sum_{j=1}^m w(x_j, S)(f(x_j, S)-y_j)^2+u \sup _j w^{\prime}(x_j, S)(f(x_j, S)-\delta(x_j, S))_{+}^2,
\end{aligned}
\]
где $u$ --- неотрицательный параметр. Весовая функция $w(x_j, S)$ выбрана таким образом, чтобы она фокусировалась только на наиболее важных документах. Во второй части уравнения $w'(x_j, S)$ выбирается так, чтобы она фокусировалась на страницах, не охваченных $w(x_j, S)$.  А $\delta(x_j, S)$ выбирается в качестве нижнего порога. Хотя $m$ часто очень велико, количество точек, при которых $w(x_j, S)$ отлично от нуля, зачастую достаточно мало. Более того, $(f(x_j, S)-\delta(x_j, S))_{+}$ не равно нулю только тогда, когда $f(x_j, S) \geq \delta(x_j, S)$.Следовательно, полностью игнорируются низкоранговые страницы,что делает алгоритм вычислительно эффективным даже при большом $m$. Формулы~(\ref{eq:LR1}) и~(\ref{eq:LR2})~\cite{LR}. 

\subsection{Ranking SVM}

Ключевая идея алгоритма, предложенного Р. Хербрихом~\cite{RankSVM}, заключается в использовании метода SVM для попарного сравнения документов на то, какой из элементов более релевантный. 

Метод опорных векторов --- алгоритм обучения с учителем, используемый для задач классификации и регрессии. Суть метода заключается в построении гиперплоскости, чтобы расстояние от неё до ближайшей точки было максимальным~\cite{ML_no_wors}. Это эквивалентно тому, что сумма расстояний до гиперплоскости от двух ближайших к ней точек, лежащих по разные стороны от неё, максимальна. На основе взаимопритяжения точки, представляющей объект, и гиперплоскости происходит  классификация.

При обучении на вход подаются набор пар вида <<точка --- метка класса>>, где метка класса это 1 или -1. Строится гиперплоскость имеющая вид $w\cdot x - b = 0$, где $x$ ---  входной вектор признаков. Так как ищется оптимальное разделение, особый интерес представляют гиперплоскости, параллельные оптимальной и ближайшие к опорным векторам двух классов. 
Можно показать, что эти параллельные гиперплоскости могут быть описаны следующими уравнениями:
\begin{equation}
		\label{eq:RSVM1}
	\begin{aligned}
		w \cdot x - b = 1  \\
		w \cdot x - b = - 1 .
	\end{aligned}
\end{equation}

Ширину полосы легко найти из соображений геометрии. Она равна $\frac{2}{||w||}$. Тогда поставленая перед нами задача состоит в минимизации $||w||$. Чем меньше $||w||$ , тем больше расстояние между этими двумя плоскостями. Большой зазор способствует лучшему обобщению, то есть качеству классификации новых данных предложенной моделью. Чтобы исключить все точки $x_i$ из полосы необходимо включить следующие ограничения:
\begin{equation}
	\label{eq:RSVM2}
	\begin{aligned}
	w \cdot x - b \geq 1, \text{если $y_i = +1$}  \\
	w \cdot x - b \leq -1, \text{если $y_i = -1$} ,
	\end{aligned}
\end{equation}
где $y_i$ --- метка.
Уравнения~(\ref{eq:RSVM2}) можно записать кратко в виде:
\begin{equation}
	\label{eq:RSVM3}
	y_i(w \cdot x - b) \geq 1.
\end{equation}

В случае линейной неразрешимости, алгоритму позволяется допускать ошибки на обучающей выборке. Для этого вводятся переменные $\xi_{i}$ характеризующие величину ошибки на объектах $x_i$ и коэффициент $C$ --- параметр, позволяющий настраивать отношение между максимизацией ширины разделяющей полосы и минимизацией суммарной ошибки. Тогда задача SVM формулируется как система~(\ref{eq:RSVM4}). Формулы~(\ref{eq:RSVM1})--(\ref{eq:RSVM3})~\cite{ML_no_wors}.

Пусть имеется функция $f(x)$, которая определяет релевантность документа относительно запроса. Тогда утверждение о том, что документ $x_{i}$ релевантнее чем документ $x_{j}$  ($x_{i} \succ x_{j}$)  эквивалентно тому, что $f(x_{i}) > f(x_{j})$. Тогда если выбрать функцию $f(x)=(\omega, x)$ то имеем, что:
\[
	f(x_{i}) > f(x_{j}) \iff (\omega, x_{i} - x_{j}) > 0.
\]

Теперь рассматривая разность векторов как новые объекты $\hat{x}_{i, j} = x_{i} - x_{j}$, получаем стандартную постановку SVM алгоритма. Теперь задача ставиться следующим образом:
\begin{equation}
\begin{cases}
	\label{eq:RSVM4}
	\frac{1}{2}\| \omega \|^2+C  \displaystyle\sum_{i=1}^{N} \xi_{i}\to min_{\omega, \xi} \\
	y_{i}(\omega, x_{i}^1 - x_{i}^2) \leq 1 - \xi_{i} \\
	\xi_{i} \geq 0 \\
\end{cases},
\end{equation}
где $N$ --- количество пар объектов, $x_{i}^1$, $x_{i}^2$ --- первый и второй объект пары соответственно. При этом $y_{i} = 1$, если $x_{i}^1 \succ x_{i}^2$, иначе  $y_{i} = -1$. Допустимы парами являются документы из одного списка  с различной степенью релевантности. Формула~(\ref{eq:RSVM4})~\cite{RankSVM}.

\subsection{LambdaRank}

В поточечных и попарных методах ранжирования итоговый функционал при обучении обычно не дифференцируется, так как он зависит от порядка элементов. В рассматриваемом алгоритме, описанном Бургес~\cite{LamdaRank}, вместо исходного функционала рассматривается непрерывный аналог, который легко оптимизировать.
Рассмотрим работу метода для одного поискового запроса. Алгоритм LambdaRank не определяет непрерывный приближенный функционал $L$, вместо этого он находит градиент функционала на всем списке документов:
\begin{equation}
	\label{eq:LBR1}
	\frac{\partial L}{\partial s_{i}} = -\lambda(s_{1}, y_{1}, \dots, s_{n}, y_{n}),
\end{equation}
гдe $s_{i}$ --- рейтинг документа, $y_{i}$ --- степень релевантности, а $n$ --- количество документов. Градиент выбранного документа зависит от рейтингов и степени релевантности. Он пересчитывается после каждой генерации списка.

Один из способов повышения эффективност алгоритма  --- увеличение градиента документов на первых позициях, то есть нужно сделать более значимыми  перестановки с первыми элементами. Для двух документов $d_{i}$ и $d_{j}$ имеем, если $d_{i} \succ d_{j}$, то $| \frac{\partial L}{\partial s_{i}} | > | \frac{\partial L}{\partial s_{j}} |$.

Метод позволяет настраиваться на широкий класс функционалов качеств, однако в стандартном варианте $\lambda$ вычисляется по метрике NDCG:
\begin{equation}
	\label{eq:LBR2}
	\lambda_{i} = \frac{\partial L}{\partial s_{i}} = \frac{1}{G_{max}} \sum_{j}(\frac{1}{1 + exp(s_{j} - s{i})})(G(y_{j}) - G(y_{i}))(D(\pi_{j}) - D(\pi_{i})),
\end{equation}
где  $G$, $D$ ---  функции преобразования релевантности документа в его рейтинг и порядковый номера  в ранжированном списке.  $\lambda_{i}$ – показывает насколько надо увеличить рейтинг $i$-го документа. Для этого необходимо изменить веса $\omega$:
\begin{equation}
	\label{eq:LBR3}
	\frac{\partial L}{\partial \omega} = \sum_{i=1}^{n}\frac{\partial s_{i}}{\partial \omega}\sum_{j \in P_{i}}\frac{\partial L(s_{i}, s_{j})}{\partial s_{i}} + \sum_{j=1}^{n}\frac{\partial s_{j}}{\partial \omega}\sum_{i \in P_{j}}\frac{\partial L(s_{i}, s_{j})}{\partial s_{j}},
\end{equation}
где $P_{i}$, $P_{i}$ --- множество пар документов с индексами $j$ и $i$, для которых пары ($i$, $j$) во множестве пар документов $P$ соответственно.

Таким образом, алгоритм LambdaRank заключается в итерационном пересчете весов $\omega$:
\begin{equation}
	\label{eq:LBR4}
	\omega = \omega - \eta\frac{\partial L}{\partial \omega},
\end{equation}
где $\eta$ --- итерационный шаг. Если запросов несколько, то необходимо расширить множество $P$, которое может быть построено как и в методе Ranking SVM. Формулы~(\ref{eq:LBR1})--(\ref{eq:LBR4})~\cite{LamdaRank}.

В данном методе для минимизации целевой функции используется градиентный спуск, суть которого заключается в использовании градиента для поиска локального минимума целевой функции. За счёт частных производных, домноженных на -1, при каждой итерации её параметры пересчитываются таким образом, что происходит движение в сторону локального минимума~\cite{ML_no_wors}.

\subsection{ListNet}
Впервые алгоритм был описан З. Као~\cite{ListNet}. Цель обучения формализована как минимизация общих потерь в отношении обучающих данных.
\begin{equation}
	\label{eq:LN1}
	\sum_{i=1}^m L(y^{(i)}, z^{(i)}),
\end{equation}
где $L$ --- функция потерь по списку.
В данном алгоритме предлагается использовать вероятностные модели для вычисления функции потерь $L$ по списку.
Пусть набор объектов, подлежащих ранжированию, идентифицируется числами $1, 2, \dots, n$. Перестановка $\pi$ на объектах определяется как биекция из $\{1, 2, \dots, n\}$ в саму себе, т.~е. $\pi=(\pi(1), \dots, \pi(n))$. Здесь $\pi(j)$ обозначает объект в позиции $j$ в перестановке. Множество всех возможных перестановок $n$ объектов обозначается как $\Omega_n$. Пусть существует функция ранжирования, которая присваивает
оценки $n$ объектам. Обозначим список оценок как $s = (s_1, s_2, \dots, s_n)$, где $s_j$ --- оценка $j$-го объекта. 

Предполагается, что возможна любая перестановка, но разные перестановки могут иметь разную вероятность, рассчитанную на основе функции ранжирования. Определим вероятность перестановки таким образом, чтобы она обладала желаемыми свойствами. Тогда вероятность перестановки $\pi$, заданная списком оценок $s$, определяется как:
\begin{equation}
	\label{eq:LN2}
	P_s(\pi)=\prod_{j=1}^n \frac{\phi(s_{\pi(j)})}{\sum_{k=j}^n \phi(s_{\pi(k)})},
\end{equation}
где $\phi(s_{\pi(j)})$ ---  оценка объекта в позиции $j$ перестановки $\pi$, $\phi$ --- возрастающая и строго положительная функция.

Для любого списка ранжирования, основанного на данной функции, если поменять позицию объекта с высоким и низким баллом местами, получим список с меньшей вероятностью перестановки. Список объектов, отсортированных на основе функции ранжирования, имеет наибольшую вероятность перестановки, в то время как список объектов, отсортированных в обратном порядке, имеет наименьшую вероятность. То есть наиболее вероятной перестановкой является, отсортированная с помощью функции ранжирования.

Имея два списка оценок, мы можем сначала вычислить из них два распределения вероятностей перестановок, а затем вычислить расстояние между двумя распределениями как функцию потерь по списку. Однако, поскольку число перестановок равно $n!$, вычисление может оказаться крайне трудозатратным.

Чтобы справиться с данной проблемой, рассмотрим использование вероятности того, что $j$-ый документ будет ранжирован выше всех, учитывая оценки остальных документов
\begin{equation}
	\label{eq:LN3}
	P_s(j)=\frac{\phi(s_j)}{\sum_{k=1}^n \phi(s_k)} .
\end{equation}
Используя перекрестную энтропию в качестве метрики, функцию потерь~(\ref{eq:LN1}) можно записать:
\begin{equation}
	\label{eq:LN4}
	L(y^{(i)}, z^{(i)})=-\sum_{j=1}^n P_{y^{(i)}}(j) \log (P_{z^{(i)}}(j)).
\end{equation}

Обозначим функцию ранжирования, основанную на модели нейронной сети $\omega$ как $f_\omega$. Функция $f_\omega$ присваивает вектору признаков $x_j^{(i)}$ значение рейтинга. Определим $\phi$ как экспоненциальную функцию, тогда функцию вероятности~(\ref{eq:LN3}) можно записать как:
\begin{equation}
	\label{eq:LN5}
	P_s(j)=\frac{\phi(s_j)}{\sum_{k=1}^n \phi(s_k)}=\frac{\exp (s_j)}{\sum_{k=1}^n \exp (s_k)}.
\end{equation}

Имея запрос $q^{(i)}$ ранжирующая функция создаёт список рейтингов \[z^{(i)}(f_\omega)=(f_\omega(x_1^{(i)}), f_\omega(x_2^{(i)}), \cdots, f_\omega(x_{n^{(i)}}^{(i)})).
\]
Тогда функцию вероятности~(\ref{eq:LN5}) можно записать как:
\begin{equation}
	\label{eq:LN6}
	P_{z^{(i)}(f_\omega)}(x_j^{(i)})=\frac{\exp (f_\omega(x_j^{(i)}))}{\sum_{k=1}^{n^{(i)}} \exp (f_\omega(x_k^{(i)}))}.
\end{equation}

С перекрестной энтропией в качестве метрики, функции потери~(\ref{eq:LN4}) примет вид:
\begin{equation}
	\label{eq:LN7}
	L(y^{(i)}, z^{(i)}(f_\omega))=-\sum_{j=1}^{n^{(i)}} P_{y^{(i)}}(x_j^{(i)}) \log (P_{z^{(i)}(f_\omega)}(x_j^{(i)})).
\end{equation}

Градиент функции потери можно найти по следующей формуле:

\begin{equation}
	\label{eq:LN8}
	\begin{aligned}
		\Delta \omega= 
		\frac{\partial L(y^{(i)}, z^{(i)}(f_\omega))}{\partial \omega}=-\sum_{j=1}^{n^{(i)}} P_{y^{(i)}}(x_j^{(i)}) \frac{\partial f_\omega(x_j^{(i)})}{\partial \omega} \\
		+\frac{1}{\sum_{j=1}^{n^{(i)}} \exp (f_\omega(x_j^{(i)}))} \sum_{j=1}^{n^{(i)}} \exp (f_\omega(x_j^{(i)})) \frac{\partial f_\omega(x_j^{(i)})}{\partial \omega}.
	\end{aligned}
\end{equation}


Метод ListNet заключается в итерационном пересчете $\Delta \omega$ и обновлении весов модели: $\omega = \omega - \eta\Delta \omega$. Используется метод градиентного спуска, описанный выше. Формулы~(\ref{eq:LN1})--(\ref{eq:LN8})~\cite{ListNet}