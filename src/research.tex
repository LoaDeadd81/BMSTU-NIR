\chapter{Исследование существующих алгоритмов \\обучения ранжированию}

\section{Классификация алгоритмов}

Существующие алгоритмы обучения ранжированию делятся на три группы по подходу к обучению~\cite{ML_for_SE}: поточечный, попарный и списочный.

Поточечный подход --- частный случай задачи регрессии или классификации, если множество оценок конечно, в ходе ее решения возможно использовать метод градиентного спуска, опорных векторов и т.~д. На практике этот подход дает не очень качественный результат, так как каждый документ ранжируется независимо от других. В качестве примеров для обучения используют пары <<признаки~---~значение релевантности>>. Данная задача может быть аппроксимирована задачей регрессии --- учитывая единственную пару <<запрос~---~документ>>, спрогнозируйте ее оценку. Точечный подход направлен на изучение функции, предсказывающей реальное значение или порядковый номер документа, используя функцию потерь.

При попарном подходе обучение ранжированию сводится к построению бинарного классификатора, которому на вход поступают два документа, соответствующих одному и тому же запросу, и требуется определить, какой из релевантнее. Классификатор должен принимать два документа в качестве входных данных, и цель состоит в том, чтобы минимизировать функцию потерь. Недостатком также является то, что данный подход не учитывает все документы запроса. Помимо этого целью обучения таких алгоритмов является минимизация ошибок в классификации пар документов, а не минимизация ошибок в ранжировании документов, процесс обучения требует больших вычислительных затрат, количество сгенерированных пар документов в значительной степени варьируется от запроса к запросу, что приводит к обучению модели, ориентированной на запросы с большим количеством пар.

Списочный подход заключается в построении модели, на вход которой поступают сразу все документы, соответствующие запросу, а на выходе получается их перестановка. Подгонка параметров модели осуществляется для прямой максимизации одной метрик ранжирования. Но это часто затруднительно, так как метрики ранжирования обычно не непрерывны и недифференцируемы относительно параметров ранжирующей модели, поэтому прибегают к максимизации неких их приближений или нижних оценок. С точки зрения поставленной задачи ранжирования, списочные методы являются методами, которые решают исходную постановку задачи. Является одним из самых лучших методов на данный момент, но они сложны в разработке и подборе обучающих наборов данных



\section{Алгоритмы обучения ранжированию}

В данном разделе будут рассмотрены несколько популярных алгоритмов из каждой категории: Linear Regression (поточечный), OC SVM (поточечный), Ranking SVM (попарный), LambdaRank(попарный), ListNet(списочный). 

Перед описанием алгоритмов стоит введём следующие обозначения:
\begin{itemize}[label=---]
	\item $q_{i}$ --- $i$-ый поисковый запрос;
	\item $D_{i}$ --- список всех документов, которые ассоциированы с $q_{i}$ запросом;
	\item $d_{i,j}$ --- $j$-ый документ из списка $D_{i}$;
	\item $\pi_{i}$ --- отсортированный список $D_{i}$;
	\item $y_{i,j}$ --- метка, показывающая на сколько документ $d_{i,j}$ релевантен к запросу $q_{i}$;
	\item $y_{i}$ --- вектор меток $y_{i,j}$.
\end{itemize}

На этапе ранжирования методы имеют схожий алгоритм. Для каждого документа $d_{i,j}$ вычисляется рейтинг релевантности, который зависит от вектора признаков документа $x_{i,j}$ и параметров метода ранжирования $\omega$. Затем рейтинги сортируются по убыванию и получается отранжированный список документов. Признаки документов зависят не только от описания документов, но и от функции от поискового запроса и
документа.

\subsection{Linear Regression}

Рассматриваем метод обучения на основе регрессии для решения задачи оптимизации метрик DCG~\cite{LR}. Пусть $F$ --- функциональное пространство, содержащее функции $X \times S \to F$, где $X$ --- множество векторов представления документов, $S$ --- множества всех конечных подмножеств $X$. Произвольно созданы множества $S_{1}, \dots, S{n}$, где $S_{i} = \{x_{i,1}, \dots, x_{i,m}\}$, с соответствующими оценками $\{y_{i,j}\}_{j} = \{y_{i,1}, \dots, y_{i,m}\}$. Тогда для решения проблемы ранжирования можно использовать простой подход, основанный на регрессии:
\[
\hat{f}=\arg \min _{f \in \mathcal{F}} \frac{1}{n} \sum_{i=1}^n[\sum_{j=1}^m(f(x_{i, j}, S_i)-y_{i, j})^2] .
\]

Однако этот метод прямой регрессии не подходит для крупномасштабных задач ранжирования, таких как веб--поиск, для которых требуется ранжировать множество элементов, но важны только страницы с самым высоким рейтингом. Это связано с тем, что метод уделяет равное внимание релевантным и нерелевантным страницам. На самом деле, следует уделять больше внимания страницам с самым высоким рейтингом. Оценки страниц с низкой релевантностью не нуждаются в большой точности, до тех пор, пока мы не переоцениваем их, чтобы эти страницы отображались на верхних позициях в поиске. С учётом этик рассуждений стоит использовать следующий метод обучения: 
\[
\hat{f}=\arg \min _{f \in \mathcal{F}} \frac{1}{n} \sum_{i=1}^n L(f, S_i,\{y_{i, j}\}_j),
\]
где для $S = \{x_{1}, \dots, x_{m}\}$, с соответствующим $\{y_{j}\}_{j}$, имеем:
\[
\begin{aligned}
	& L(f, S,\{y_j\}_j) \\
	= & \sum_{j=1}^m w(x_j, S)(f(x_j, S)-y_j)^2+u \sup _j w^{\prime}(x_j, S)(f(x_j, S)-\delta(x_j, S))_{+}^2,
\end{aligned}
\]
где $u$ --- неотрицательный параметр. Весовая функция $w(x_j, S)$ выбрана таким образом, чтобы она фокусировалась только на наиболее важных документах. Во второй части уравнения мы выбирается $w'(x_j, S)$ так, чтобы она фокусировалась на страницах, не охваченных $w(x_j, S)$. $\delta(x_j, S)$ выбирается в качестве нижнего порога. Важной особенностью является то, что, хотя $m$ часто очень велико, количество точек, при которых $w(x_j, S)$ отлично от нуля, зачастую достаточно мало. Более того, $(f(x_j, S)-\delta(x_j, S))_{+}$ не равно нулю только тогда, когда $f(x_j, S) \geq \delta(x_j, S)$.Следовательно, полностью игнорируются низкоранговые страницы,что делает алгоритм вычислительно эффективным даже при большом $m$. 



\subsection{OC SVM}

OC SVM  является одним из базовых алгоритмов ранжирования. Алгоритм заключается в построении гиперплоскостей, которые выступают в роли разделителей. По взаиморасположение документа $d_{i,j}$ и гиперплоскостей делается предсказание о степени релевантности документа. 
Перегруппировав все векторные представления документов $x_{i,j}$ по степени релевантности, получим $\hat{x}_{r,k}$ --- вектор признаков $k$-ого по счету документа, у которого степень релевантности равна $r = y_{r,k}$, и пусть таких документов $m_{r}$. Тогда задачу поиска таких $\omega$ и $b_{r}$ можно поставить следующим образом:
\[
\begin{cases}
	\frac{1}{2}\| \omega \|^2+C  \displaystyle\sum_{r=1}^{l-1} \displaystyle\sum_{k=1}^{m_{r}} (\xi_{r, k}+\hat{\xi}_{r,k})\to min_{\omega, b, \xi, \hat{\xi}} \\
	(\omega, \hat{x}_{r,k}) - b_{r} \leq -1 + \xi_{r, k} \\
	(\omega, \hat{x}_{r,k}) - b_{r} \leq 1 + \hat{\xi}_{r,k} \\
	\xi_{r, k}, \hat{\xi}_{r,k} \geq 0 \\
\end{cases},
\]
где $\xi_{r, k}$ характеризует величину ошибки для $x_{r,k}$, $C$ --- параметр, позволяющий регулировать отношение между максимизацией ширины разделяющей полосы и минимизацией суммарной ошибки. Получается стандартная задача квадратичного программирования. Алгоритм пытается проводить гиперплоскости, с максимальным отступом от элементов.

\subsection{Ranking SVM}

Ключевая идея алгоритма, предложенного Р. Хербрихом~\cite{RankSVM}, заключается в использовании метода SVM для попарного сравнения документов на то, какой из элементов более релевантный. 

Пусть имеется функция $f(x)$, которая определяет релевантность документа относительно запроса. Тогда утверждение о том, что документ $x_{i}$ релевантнее чем документ $x_{j}$  ($x_{i} \succ x_{j}$)  эквивалентно тому, что $f(x_{i}) > f(x_{j})$. Тогда если выбрать функцию $f(x)=(\omega, x)$ то имеем, что:
\[
	f(x_{i}) > f(x_{j}) \iff (\omega, x_{i} - x_{j}) > 0.
\]

Теперь рассматривая разность векторов как новые объекты $\hat{x}_{i, j} = x_{i} - x_{j}$, получаем стандартную постановку SVM алгоритма. Теперь задача ставиться следующим образом:
\[
\begin{cases}
	\frac{1}{2}\| \omega \|^2+C  \displaystyle\sum_{i=1}^{N} \xi_{i}\to min_{\omega, \xi} \\
	y_{i}(\omega, x_{i}^1 - x_{i}^2) \leq 1 - \xi_{i} \\
	\xi_{i} \geq 0 \\
\end{cases},
\]
где $N$ --- количество пар объектов, $x_{i}^1$, $x_{i}^2$ --- первый и второй объект пары соответственно. При этом $y_{i} = 1$, если $x_{i}^1 \succ x_{i}^2$, иначе  $y_{i} = -1$. Допустимы парами являются документы из одного списка и с различной степенью релевантности.

\subsection{LambdaRank}

В поточечных и попарных методах ранжирования итоговый функционал при обучении обычно не дифференцируемый, так как зависит от порядка элементов. В рассматриваемом алгоритме, описанном Бургес~\cite{LamdaRank}, вместо исходного функционала рассматривается непрерывный аналог, который легко оптимизировать.
Рассмотрим работу метода для одного поискового запроса. Алгоритм LambdaRank не определяет непрерывный приближенный функционал $L$, вместо этого он определяет градиент функционала на всем списке документов:
\[
\frac{\partial L}{\partial s_{i}} = -\lambda(s_{1}, y_{1}, \dots, s_{n}, y_{n}),
\]
гдe $s_{i}$ --- рейтинг документа, $y_{i}$ --- степень релевантности, а $n$ --- количество документов. Градиент выбранного документу зависит от рейтингов и степени релевантности других\ и пересчитывается после каждой генерации списка.

Один из способов добиться повышения эффективности --- увеличение градиента документов на первых позициях, то есть более значимыми сделать перестановки с первыми элементами. Для двух документов $d_{i}$ и $d_{j}$ имеем, если $d_{i} \succ d_{j}$, то $| \frac{\partial L}{\partial s_{i}} | > | \frac{\partial L}{\partial s_{j}} |$.

Метод позволяет настраиваться на широкий класс функционалов качеств, однако в стандартном варианте $\lambda$ вычисляется по метрике NDCG:
\[
\lambda_{i} = \frac{\partial L}{\partial s_{i}} = \frac{1}{G_{max}} \sum_{j}(\frac{1}{1 + exp(s_{j} - s{i})})(G(y_{j}) - G(y_{i}))(D(\pi_{j}) - D(\pi_{i})),
\]
где функции $G$, $D$ ---  функции преобразования релевантности документа в его рейтинг и порядковой номера документа в ранжированном списке.  $\lambda_{i}$ – показывает насколько надо увеличить рейтинг $i$-го документа. Для этого надо изменить веса $\omega$:
\[
\frac{\partial L}{\partial \omega} = \sum_{i=1}^{n}\frac{\partial s_{i}}{\partial \omega}\sum_{j \in P_{i}}\frac{\partial L(s_{i}, s_{j})}{\partial s_{i}} + \sum_{j=1}^{n}\frac{\partial s_{j}}{\partial \omega}\sum_{i \in P_{j}}\frac{\partial L(s_{i}, s_{j})}{\partial s_{j}},
\]
где $P_{i}$, $P_{i}$ --- множество пар документов с индексами $j$ и $i$, для которых пары ($i$, $j$) во множестве пар документов $P$ соответственно.

Таким образом, алгоритм LambdaRank заключается в итерационном пересчете весов $\omega$:
\[
\omega = \omega - \eta\frac{\partial L}{\partial \omega},
\]
где $\eta$ --- итерационный шаг.  Если запросов несколько, то необходимо расширить множество $P$, которое может быть
построено как и в методе Ranking SVM.

\subsection{ListNet}
Впервые алгоритм был описан З. Као~\cite{ListNet}.Цель обучения формализована как минимизация общих потерь в отношении обучающих данных. 
\[
\sum_{i=1}^m L(y^{(i)}, z^{(i)}),
\]
где $L$ --- функция потерь по списку.
В данном алгоритме предлагается использовать вероятностные модели для вычисления функции потерь $L$ по списку.
Пусть набор объектов, подлежащих ранжированию, идентифицируется числами $1, 2, \dots, n$. Перестановка $\pi$ на объектах определяется как биекция от $\{1, 2, \dots, n\}$ к самой себе, т.~е. $\pi=(\pi(1), \dots, \pi(n))$. Здесь $\pi(j)$ обозначает объект в позиции $j$ в перестановке. Множество всех возможных перестановок $n$ объектов обозначается как $\Omega_n$. Пусть существует функция ранжирования, которая присваивает
оценки $n$ объектам. Обозначим список оценок как $s = (s_1, s_2, \dots, s_n)$, где $s_j$ --- оценка $j$-го объекта. 

Предполагается, что возможна любая перестановка, но разные перестановки могут иметь разную вероятность, рассчитанную на основе функции ранжирования. Определим вероятность перестановки таким образом, чтобы она обладала желаемыми свойствами. Тогда вероятность перестановки $\pi$, заданная списком оценок $s$, определяется как:
\[
P_s(\pi)=\prod_{j=1}^n \frac{\phi(s_{\pi(j)})}{\sum_{k=j}^n \phi(s_{\pi(k)})},
\]
где $\phi(s_{\pi(j)})$ --- это оценка объекта в позиции $j$ перестановки $\pi$, $\phi$ --- возрастающая и строго положительная функция.

Для любого списка ранжирования, основанного на данной функции, если поменять позицию объекта с высоким и низким баллом местами, получим список с меньшей вероятностью перестановки. Список объектов, отсортированных на основе функции ранжирования, имеет наибольшую вероятность перестановки, в то время как список объектов, отсортированных в обратном порядке, имеет наименьшую вероятность. То есть наиболее вероятной перестановкой является, отсортированная с помощью функции ранжирования.

Имея два списка оценок, мы можем сначала вычислить из них два распределения вероятностей перестановок, а затем вычислить расстояние между двумя распределениями как функцию потерь по списку. Однако, поскольку число перестановок равно $n!$, вычисление может оказаться крайне трудозатратным.

Чтобы справиться с данной проблемой, рассмотрим использование вероятности того, что $j$-ый документ будет ранжирован выше всех, учитывая оценки остальных документов
\[
P_s(j)=\frac{\phi(s_j)}{\sum_{k=1}^n \phi(s_k)} .
\]
Используя перекрестную энтропию в качестве метрики, функцию потерь можно записать в как:
\[
L(y^{(i)}, z^{(i)})=-\sum_{j=1}^n P_{y^{(i)}}(j) \log (P_{z^{(i)}}(j)).
\]

Обозначим функцию ранжирования, основанную на модели нейронной сети $\omega$ как $f_\omega$. Функция $f_\omega$ присваивает вектору признаков $x_j^{(i)}$ значение рейтинга. Определим $\phi$ как экспоненциальную функцию, тогда
\[
P_s(j)=\frac{\phi(s_j)}{\sum_{k=1}^n \phi(s_k)}=\frac{\exp (s_j)}{\sum_{k=1}^n \exp (s_k)}.
\]

Имея запрос $q^{(i)}$ ранжирующая функция создаёт список рейтингов \[z^{(i)}(f_\omega)=(f_\omega(x_1^{(i)}), f_\omega(x_2^{(i)}), \cdots, f_\omega(x_{n^{(i)}}^{(i)})).
\]
Тогда функция вероятности можно записать как:
\[
P_{z^{(i)}(f_\omega)}(x_j^{(i)})=\frac{\exp (f_\omega(x_j^{(i)}))}{\sum_{k=1}^{n^{(i)}} \exp (f_\omega(x_k^{(i)}))}.
\]

С перекрестной энтропией в качестве метрики, функции потери примет вид
\[
L(y^{(i)}, z^{(i)}(f_\omega))=-\sum_{j=1}^{n^{(i)}} P_{y^{(i)}}(x_j^{(i)}) \log (P_{z^{(i)}(f_\omega)}(x_j^{(i)}))
\]

Градиент функции потери можно найти по следующей формуле:
\[
\begin{aligned}
	\Delta \omega= & \frac{\partial L(y^{(i)}, z^{(i)}(f_\omega))}{\partial \omega}=-\sum_{j=1}^{n^{(i)}} P_{y^{(i)}}(x_j^{(i)}) \frac{\partial f_\omega(x_j^{(i)})}{\partial \omega} \\
	& +\frac{1}{\sum_{j=1}^{n^{(i)}} \exp (f_\omega(x_j^{(i)}))} \sum_{j=1}^{n^{(i)}} \exp (f_\omega(x_j^{(i)})) \frac{\partial f_\omega(x_j^{(i)})}{\partial \omega}
\end{aligned}
\]

Метод ListNet заключается в итерационном пересчете $\Delta \omega$ и обновлении весов
модели: $\omega = \omega - \eta\Delta \omega$.