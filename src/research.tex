\chapter[Исследование существующих алгоритмов обучения\\ранжированию]{Исследование существующих алгоритмов \\обучения ранжированию}

\section{Классификация алгоритмов}

Существующие алгоритмы обучения ранжированию делятся на три \\ группы~\cite{ML_for_rank}: поточечный, попарный и списочный.

Поточечный подход --- частный случай задачи регрессии или классификации. На практике поточечный подход дает не очень качественный результат, так как каждый документ ранжируется независимо от других. В качестве примеров для обучения используют пары <<признаки~---~значение релевантности>>. Точечный подход направлен на обучение модели, предсказывающей значение релевантности или порядковый номер документа. Окончательное ранжирование достигается путем простой сортировки списка результатов по оценке документа, выданной обученной моделью~\cite{ML_for_SE}.

При попарном подходе обучение ранжированию сводится к построению бинарного классификатора, которому на вход поступают два документа, соответствующих одному и тому же запросу, и требуется определить, какой из них будет более релевантным. Недостатком  является невозможность учета сразу всех документов запроса. Целью обучения таких алгоритмов является минимизация ошибок в классификации пар документов, а не в их ранжировании. Процесс обучения требует больших вычислительных затрат, поскольку количество пар документов очень велико. Количество сгенерированных пар документов в значительной степени варьируется от запроса к запросу, что приводит к обучению модели, ориентированной на запросы с большим количеством пар, то есть обучается неравномерно. В итоге результаты ранжирования для запросов похожих на запросы из обучающие выборки, которые имеют меньшее количеством пар документов, будут значительно хуже. При ранжировании алгоритмы получают пару документов на вход и определяет их порядок относительно друг друга~\cite{ML_for_SE}.

Списочный подход заключается в построении модели, на вход которой поступают сразу все документы, соответствующие запросу, а на выходе получается отранжированная перестановка этих документов. Подгонка параметров модели осуществляется для прямой максимизации одной из  метрик ранжирования. Но это затруднительно, так как метрики ранжирования обычно не непрерывны и недифференцируемы относительно параметров ранжирующей модели, поэтому прибегают к максимизации неких их приближений или нижних оценок. С точки зрения поставленной задачи ранжирования, списочные методы  решают её исходную постановку. Они обладают одними из лучших показателей метрик, оценивающих ранжирование, на данный момент, но  сложны в разработке и подборе обучающих наборов данных. При списочном подходе алгоритмы непосредственно просматривают весь список документов и подбирают для него оптимальный порядок~\cite{ML_for_SE}.

\section{Алгоритмы обучения ранжированию}

В данном разделе будут рассмотрены несколько популярных алгоритмов из каждой категории: Linear Regression (поточечный), Ranking SVM (попарный), LambdaRank(попарный), ListNet(списочный). 

Перед описанием алгоритмов введём следующие обозначения:
\begin{itemize}[label=---]
	\item $q_{i}$ --- $i$-ый поисковый запрос;
	\item $D_{i}$ --- список всех документов, которые ассоциированы с $q_{i}$ запросом;
	\item $d_{i,j}$ --- $j$-ый документ из списка $D_{i}$;
	\item $\pi_{i}$ --- отсортированный список $D_{i}$;
	\item $y_{i,j}$ --- метка, показывающая релевантность документа $d_{i,j}$  запросу $q_{i}$;
	\item $y_{i}$ --- вектор меток $y_{i,j}$.
\end{itemize} 

При ранжировании документов признаки формируются не только на основании документа или запроса по отдельности, но и как функция от поискового запроса и документа в совокупности. Такие признаки способны хорошо показывать степень релевантности документа запросу, так как лучше отображают связь запроса и документа.
Зачастую используются следующие признаки:
\begin{itemize}[label=---]
	\item текстовые --- описывают количество и место слов встречающихся в документе и запросе. Используются меры, такие как TF-IDF, используемая для оценки важности слов в контексте документа, BM 25 и различные языковые модели;
	\item ссылочные --- описывают количество гиперссылок на документ на других сайтах и сколько внутри самого документа полезных ссылок, удовлетворяющих запросу. Мера PageRank назначает каждому документу некоторое численное значение, измеряющее его «важность» или «авторитетность» среди остальных документов основываясь на информации о гиперссылках на эту страницу.   HITS позволяет находить страницы, соответствующие запросу пользователя, на основе информации, заложенной в ссылках, находящихся в документе. Идея основана на предположении, что гиперссылки кодируют значительное количество скрытых сайтов соответствующих запросу пользователя. Рекурсивно просматривая ссылки, находящиеся на странице, алгоритм оценивает их содержание и в соответствии с этим переоценивает страницу, содержащую эти ссылки;
	\item кликовые --- описывают количество кликов пользователей на документ в поисковой выдаче. Учитывается как общее количество кликов, так и по какому-то определённому запросу.
\end{itemize}

\subsection{Алгоритм Linear Regression}

 Метод обучения на основе регрессии используется для решения задачи оптимизации метрик DCG~\cite{LR}. Пусть $\mathcal{F}$ --- функциональное пространство, содержащее функции $X \times S \to \mathcal{F}$, где $X$ --- множество векторов представления документов, $S$ --- множества всех конечных подмножеств $X$. Произвольно созданы множества $S_{1}, \dots, S{n}$, где $S_{i} = \{x_{i,1}, \dots, x_{i,m}\}$, с соответствующими оценками $\{y_{i,j}\} = \{y_{i,1}, \dots, y_{i,m}\}$. Тогда для решения проблемы ранжирования можно использовать простой подход, основанный на регрессии:
\begin{equation}
	\label{eq:LR1}
	\hat{f}=\arg \min _{f \in \mathcal{F}} \frac{1}{n} \sum_{i=1}^n[\sum_{j=1}^m(f(x_{i, j}, S_i)-y_{i, j})^2].
\end{equation}

Регрессия --- задача прогнозирования метки по набору признаков объектов. Метка здесь может принимать любое значение. Алгоритм моделирует зависимость меток от признаков, чтобы определить закономерности изменения меток в зависимости характеристик объекта. При обучении алгоритму на вход подаются примеры с известными метками. Результатом работы является функция, способная прогнозировать значение метки для новых данных~\cite{ML_no_wors}. 

Для возможности предсказания меток в регрессии гиперплоскость проводится так, чтобы  она оказалась как можно ближе к обучающим примерам, которые представляют собой точку в пространстве размерностью равной длине вектора характеристик каждого объекта~\cite{ML_no_wors}. Для этого требуется минимизировать целевую функцию~(\ref{eq:LR1}). Выражение $(f(x_{i, j}, S_i)-y_{i, j})^2$ называют функцией потерь, в данном случае используется квадратичная функция потерь. Она определяет величину штрафа за неправильную классификацию. В этом алгоритме функция стоимости определена как средняя потеря. Минимизировав целевую функцию получим оптимальные параметры модели, для предсказания значения метки.

Однако метод прямой регрессии не подходит для крупномасштабных задач ранжирования, таких как веб-поиск, для которых требуется ранжировать множество элементов. Хорошим результатом работы такого алгоритма будет выбор страниц с самым высоким рейтингом. Данный метод уделяет равное внимание релевантным и нерелевантным страницам. На самом деле, следует уделять больше внимания страницам с самым высоким рейтингом. Оценка страниц с низкой релевантностью не нуждается в большой точности, до тех пор, пока не происходит новая оценка их релевантности для того, чтобы эти страницы отображались на верхних позициях в поиске. С учётом этих рассуждений стоит изменить формулу~(\ref{eq:LR1}) следующим образом:
\begin{equation}
			\label{eq:LR2}
		\hat{f}=\arg \min _{f \in \mathcal{F}}
		\frac{1}{n} \sum_{i=1}^n L(f, S_i,\{y_{i, j}\}),
\end{equation}
где для $S = \{x_{1}, \dots, x_{m}\}$, с соответствующим $\{y_{j}\}$, имеем функцию потерь:
\[
\begin{aligned}
	& L(f, S,\{y_j\})= \\
	= & \sum_{j=1}^m w(x_j, S)(f(x_j, S)-y_j)^2+u \max_j w^{\prime}(x_j, S)(f(x_j, S)-\delta(x_j, S))_{+}^2,
\end{aligned}
\]
где $u$ --- неотрицательный параметр. Весовая функция $w(x_j, S)$ выбрана таким образом, чтобы она фокусировалась только на наиболее важных документах. Во второй части уравнения $w'(x_j, S)$ выбирается так, чтобы она фокусировалась на страницах, не охваченных $w(x_j, S)$.  А $\delta(x_j, S)$ выбирается в качестве нижнего порога. Хотя $m$ часто очень велико, количество точек, при которых $w(x_j, S)$ отлично от нуля, зачастую достаточно мало. Более того, $(f(x_j, S)-\delta(x_j, S))_{+}$ не равно нулю только тогда, когда $f(x_j, S) \geq \delta(x_j, S)$.Следовательно, полностью игнорируются низкоранговые страницы, что делает алгоритм более эффективным даже при большом $m$. Формулы~(\ref{eq:LR1}) и~(\ref{eq:LR2})~\cite{LR}. 

\subsection{Алгоритм Ranking SVM}

Ключевая идея алгоритма, предложенного Р. Хербрихом~\cite{RankSVM}, заключается в использовании метода опорных векторов для попарного сравнения документов на то, какой из элементов более релевантен запросу. 

Метод опорных векторов --- алгоритм обучения с учителем, используемый для задач классификации. Суть метода заключается в построении гиперплоскости так, чтобы расстояние от неё до ближайшей точки было максимальным~\cite{ML_no_wors}. Это эквивалентно тому, что сумма расстояний до гиперплоскости от двух ближайших к ней точек, лежащих по разные стороны от неё, максимальна. На основе взаимоположения точки, представляющей объект, и гиперплоскости происходит  классификация.

При обучении на вход подаются набор пар вида <<точка --- метка класса>>, где метка класса это $1$ или $-1$. Строится гиперплоскость имеющая вид $w\cdot x - b = 0$, где $x$ ---  входной вектор признаков. Так как ищется оптимальное разделение, особый интерес представляют гиперплоскости, параллельные оптимальной и ближайшие к опорным векторам двух классов. 
Можно показать, что эти параллельные гиперплоскости могут быть описаны следующими уравнениями:
\begin{equation}
		\label{eq:RSVM1}
	\begin{aligned}
		w \cdot x - b = 1,  \\
		w \cdot x - b = - 1 .
	\end{aligned}
\end{equation}

Ширину полосы легко найти из соображений геометрии. Она равна $\frac{2}{||w||}$. Тогда поставленая перед нами задача состоит в минимизации $||w||$. Чем меньше $||w||$ , тем больше расстояние между этими двумя плоскостями. Большой зазор способствует лучшему обобщению, то есть качеству классификации новых данных предложенной моделью. Чтобы исключить все точки $x_i$ из полосы необходимо включить следующие ограничения:
\begin{equation}
	\label{eq:RSVM2}
	\begin{aligned}
	w \cdot x - b \geq 1, \text{если $y_i = +1$},  \\
	w \cdot x - b \leq -1, \text{если $y_i = -1$} ,
	\end{aligned}
\end{equation}
где $y_i$ --- метка.
Уравнения~(\ref{eq:RSVM2}) можно записать кратко в виде:
\begin{equation}
	\label{eq:RSVM3}
	y_i(w \cdot x - b) \geq 1.
\end{equation}

В случае линейной неразрешимости, алгоритму позволяется допускать ошибки на обучающей выборке. Для этого вводятся переменные $\xi_{i}$ характеризующие величину ошибки на объектах $x_i$ и коэффициент $C$ --- параметр, позволяющий настраивать отношение между максимизацией ширины разделяющей полосы и минимизацией суммарной ошибки. Тогда задача SVM формулируется как система~(\ref{eq:RSVM4}). Формулы~(\ref{eq:RSVM1})--(\ref{eq:RSVM3})~\cite{ML_no_wors}.

Пусть имеется функция $f(x)$, которая определяет релевантность документа относительно запроса. Тогда утверждение о том, что документ $x_{i}$ релевантнее чем документ $x_{j}$  ($x_{i} \succ x_{j}$)  эквивалентно тому, что $f(x_{i}) > f(x_{j})$. Тогда если выбрать функцию $f(x)=(\omega, x)$ то имеем, что:
\[
	f(x_{i}) > f(x_{j}) \iff (\omega, x_{i} - x_{j}) > 0.
\]

Теперь рассматривая разность векторов как новые объекты $\hat{x}_{i, j} = x_{i} - x_{j}$, получаем стандартную постановку SVM алгоритма. Теперь задача ставится следующим образом:
\begin{equation}
\begin{cases}
	\label{eq:RSVM4}
	\frac{1}{2}\| \omega \|^2+C  \displaystyle\sum_{i=1}^{N} \xi_{i}\to \min_{\omega, \xi}, \\
	y_{i}(\omega, x_{i}^1 - x_{i}^2) \leq 1 - \xi_{i}, \\
	\xi_{i} \geq 0, \\
\end{cases}
\end{equation}
где ~~$N$ --- количество пар объектов;

$x_{i}^1$, $x_{i}^2$ --- первый и второй объект пары соответственно. 

При этом $y_{i} = 1$, если $x_{i}^1 \succ x_{i}^2$, иначе  $y_{i} = -1$. Допустимы парами являются документы из одного списка  с различной степенью релевантности. Формула~(\ref{eq:RSVM4})~\cite{RankSVM}.

\subsection{Алгоритм LambdaRank}

В поточечных и попарных методах ранжирования итоговый функционал при обучении обычно не дифференцируется, так как он зависит от порядка элементов. Рассмотрим работу метода для одного поискового запроса. В данном алгоритме, описанном Бургесом~\cite{LamdaRank}, не определяется непрерывное приближение функционала $L$, вместо этого используется градиент функционала на всем списке документов:
\begin{equation}
	\label{eq:LBR1}
	\frac{\partial L}{\partial s_{i}} = -\lambda(s_{1}, y_{1}, \dots, s_{n}, y_{n}),
\end{equation}
гдe ~~$s_{i}$ --- рейтинг документа;

$y_{i}$ --- степень релевантности;

$n$ --- количество документов. 

Градиент выбранного документа зависит от рейтингов и степени релевантности. Он пересчитывается после каждой генерации списка.

Один из способов повышения эффективность алгоритма  --- увеличение градиента документов на первых позициях. Для двух документов $d_{i}$ и $d_{j}$ имеем, если $d_{i} \succ d_{j}$, то $| \frac{\partial L}{\partial s_{i}} | > | \frac{\partial L}{\partial s_{j}} |$.

Метод позволяет настраиваться на широкий класс функционалов качеств, однако в стандартном варианте $\lambda$ вычисляется по метрике NDCG:
\begin{equation}
	\label{eq:LBR2}
	\lambda_{i} = \frac{\partial L}{\partial s_{i}} = \frac{1}{G_{max}} \sum_{j}(\frac{1}{1 + \exp(s_{j} - s{i})})(G(y_{j}) - G(y_{i}))(D(\pi_{j}) - D(\pi_{i})),
\end{equation}
где  $G$, $D$ ---  функции преобразования релевантности документа в его рейтинг и значимости порядкового номера документа в ранжированном списке.  $\lambda_{i}$~---~показывает насколько надо увеличить рейтинг $i$-го документа. Для этого необходимо изменить веса $\omega$:
\begin{equation}
	\label{eq:LBR3}
	\frac{\partial L}{\partial \omega} = \sum_{i=1}^{n}\frac{\partial s_{i}}{\partial \omega}\sum_{j \in P_{i}}\frac{\partial L(s_{i}, s_{j})}{\partial s_{i}} + \sum_{j=1}^{n}\frac{\partial s_{j}}{\partial \omega}\sum_{i \in P_{j}}\frac{\partial L(s_{i}, s_{j})}{\partial s_{j}},
\end{equation}
где $P_{i}$, $P_{i}$ --- множество пар документов с индексами $j$ и $i$, для которых существуют пары ($i$, $j$) во множестве пар документов $P$, соответственно.

Таким образом, алгоритм LambdaRank заключается в итерационном пересчете весов $\omega$:
\begin{equation}
	\label{eq:LBR4}
	\omega = \omega - \eta\frac{\partial L}{\partial \omega},
\end{equation}
где $\eta$ --- итерационный шаг. Если запросов несколько, то необходимо расширить множество $P$, которое может быть построено как и в методе Ranking SVM. Формулы~(\ref{eq:LBR1})--(\ref{eq:LBR4})~\cite{LamdaRank}.

В данном методе для минимизации целевой функции используется градиентный спуск, суть которого заключается в использовании градиента для поиска локального минимума целевой функции. За счёт частных производных, домноженных на $-1$, при каждой итерации её параметры пересчитываются таким образом, что происходит движение в сторону локального минимума~\cite{ML_no_wors}.

\subsection{Алгоритм ListNet}
Впервые алгоритм был описан З. Као~\cite{ListNet}. Цель обучения формализована как минимизация общих потерь в отношении обучающих данных.
\begin{equation}
	\label{eq:LN1}
	\sum_{i=1}^m L(y^{(i)}, z^{(i)}),
\end{equation}
где ~~$L$ --- функция потерь по списку;

$y^{(i)}$ --- эталонный список рейтингов;

$z^{(i)}$ --- список рейтингов, созданный ранжирующей моделью.

В данном алгоритме предлагается использовать вероятностные модели для вычисления функции потерь $L$ по списку. Пусть набор объектов, подлежащих ранжированию, идентифицируется числами $1, 2, \dots, n$. Перестановка $\pi$ на объектах определяется как биекция из $\{1, 2, \dots, n\}$ в саму себе, т.~е. $\pi=(\pi(1), \dots, \pi(n))$. Здесь $\pi(j)$ обозначает объект в позиции $j$ в перестановке. Множество всех возможных перестановок из $n$ объектов обозначается как $\Omega_n$. Пусть существует функция ранжирования, которая присваивает
оценки $n$ объектам. Обозначим список оценок как $s = (s_1, s_2, \dots, s_n)$, где $s_j$ --- оценка $j$-го объекта. 

Предполагается, что возможна любая перестановка, но разные перестановки могут иметь разную вероятность. Определим вероятность перестановки таким образом, чтобы она обладала желаемыми свойствами. Тогда вероятность перестановки $\pi$, заданная списком оценок $s$, определяется как:
\begin{equation}
	\label{eq:LN2}
	P_s(\pi)=\prod_{j=1}^n \frac{\phi(s_{\pi(j)})}{\sum_{k=j}^n \phi(s_{\pi(k)})},
\end{equation}
где ~~$s_{\pi(j)}$ ---  оценка объекта в позиции $j$ перестановки $\pi$;

$\phi$ --- возрастающая и строго положительная функция.

Для любого списка, если поменять позицию объекта с высоким и низким баллом местами, получим список с меньшей вероятностью перестановки. Список объектов, отсортированных на основе функции ранжирования, имеет наибольшую вероятность перестановки, вычисленную по формуле~(\ref{eq:LN2}), в то время как список объектов, отсортированных в обратном порядке, имеет наименьшую вероятность.

Имея два списка оценок, мы можем сначала вычислить из них распределения вероятностей перестановок, а затем вычислить расстояние между двумя распределениями как функцию потерь по списку. Однако, поскольку число перестановок равно $n!$, вычисление может оказаться крайне трудозатратным.

Чтобы справиться с данной проблемой, рассмотрим использование вероятности того, что $j$-ый документ будет ранжирован выше всех, учитывая оценки остальных документов
\begin{equation}
	\label{eq:LN3}
	P_s(j)=\frac{\phi(s_j)}{\sum_{k=1}^n \phi(s_k)} .
\end{equation}
Используя перекрестную энтропию в качестве метрики, функцию потерь~(\ref{eq:LN1}) можно записать:
\begin{equation}
	\label{eq:LN4}
	L(y^{(i)}, z^{(i)})=-\sum_{j=1}^n P_{y^{(i)}}(j) \log (P_{z^{(i)}}(j)).
\end{equation}

Обозначим функцию ранжирования, основанную на модели $\omega$ как $f_\omega$. Функция $f_\omega$ присваивает вектору признаков $x_j^{(i)}$ значение рейтинга. Определим $\phi$ как экспоненциальную функцию, тогда функцию вероятности~(\ref{eq:LN3}) можно записать как:
\begin{equation}
	\label{eq:LN5}
	P_s(j)=\frac{\phi(s_j)}{\sum_{k=1}^n \phi(s_k)}=\frac{\exp (s_j)}{\sum_{k=1}^n \exp (s_k)}.
\end{equation}

Имея запрос $q^{(i)}$ ранжирующая функция создаёт список рейтингов \[z^{(i)}(f_\omega)=(f_\omega(x_1^{(i)}), f_\omega(x_2^{(i)}), \cdots, f_\omega(x_{n^{(i)}}^{(i)})).
\]
Тогда функцию вероятности~(\ref{eq:LN5}) можно записать как:
\begin{equation}
	\label{eq:LN6}
	P_{z^{(i)}(f_\omega)}(x_j^{(i)})=\frac{\exp (f_\omega(x_j^{(i)}))}{\sum_{k=1}^{n^{(i)}} \exp (f_\omega(x_k^{(i)}))}.
\end{equation}

С перекрестной энтропией в качестве метрики, функции потери~(\ref{eq:LN4}) примет вид:
\begin{equation}
	\label{eq:LN7}
	L(y^{(i)}, z^{(i)}(f_\omega))=-\sum_{j=1}^{n^{(i)}} P_{y^{(i)}}(x_j^{(i)}) \log (P_{z^{(i)}(f_\omega)}(x_j^{(i)})).
\end{equation}

Градиент функции потери можно найти по следующей формуле:
\begin{equation}
	\label{eq:LN8}
	\begin{aligned}
		\frac{\partial L}{\partial \omega}= 
		\frac{\partial L(y^{(i)}, z^{(i)}(f_\omega))}{\partial \omega}=-\sum_{j=1}^{n^{(i)}} P_{y^{(i)}}(x_j^{(i)}) \frac{\partial f_\omega(x_j^{(i)})}{\partial \omega}+ \\
		+\frac{1}{\sum_{j=1}^{n^{(i)}} \exp (f_\omega(x_j^{(i)}))} \sum_{j=1}^{n^{(i)}} \exp (f_\omega(x_j^{(i)})) \frac{\partial f_\omega(x_j^{(i)})}{\partial \omega}.
	\end{aligned}
\end{equation}


Метод ListNet заключается в итерационном пересчете $\frac{\partial L}{\partial \omega}$ и обновлении весов модели: $\omega = \omega - \eta\frac{\partial L}{\partial \omega}$. Используется метод градиентного спуска, описанный выше. Формулы~(\ref{eq:LN1})--(\ref{eq:LN8})~\cite{ListNet}.