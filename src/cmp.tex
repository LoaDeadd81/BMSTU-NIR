\chapter{Сравнение алгоритмов обучения ранжированию}

\section{Критерии сравнения}

В качестве критериев сравнения используются основные метрики оценки качества ранжирования: MAP, NDCG~\cite{metrics}. 

Рассмотрим множество документов $D$. Для каждого запроса $q$ результатом работы алгоритма ранжирования будет отображение $f: d \to R$, ставящее в соответствие каждой странице ей рейтинг, который тем больше, чем больше документ $d$ подходит к запросу $q$. Для оценки качества ранжирования нужен эталон $r_t(d)$, с которым будут сравниваться результаты.
 
MAP --- метрика средней точности нахождения релевантных документов. Данная метрика применяется в том случае, если $r_t(d)$ принимает бинарные значения, т.~е. каждый документ полностью либо релевантен либо нет.

Precision at $N$ или точность на $N$ элементах позволяет оценить долю релевантных документов среди первых $N$ элементов ранжированного списка и рассчитывается по формуле:
\[
p @ N=\frac{1}{N} \sum_{k=1}^N r_t(P^{\prime}(k)),
\]
где $P^{\prime}$ --- обратная перестановка, то есть $P^{\prime}(k)$ --- документ на $k$-ом месте после ранжированя.

Average precision at $N$ позволяет учесть место, на котором оказался документ в ранжированном списке. Гораздо важнее увидеть релевантный документ на 1-ой позиции, чем в конце списка. Формула качества принимает
следующий вид: 
\[
ap @ N=\frac{1}{N} \sum_{k=1}^N [r_t(P^{\prime}(k)) \cdot p@k],
\]
Данная величина уже зависит от порядка. Она достигает максимума, если все релевантные документы находятся вверху ранжированного списка.

Mean average precision at $N$, в отличии от предыдущих метрик вычисляется сразу для все запросов множества $Q$ и является их средним. Пусть $|Q| = K$, тогда метрика записывается как:
\[
map @ N=\frac{1}{K} \sum_{j=1}^K ap @ N_j,
\]

В отличии от предыдущей группы метрик рассмотренные ниже NDCG можно использовать и при небинарных значениях $r_t$.

Cumulative gain at $N$. В простейшем случае суммируем все значения релевантностей документов среди N первых.
\[
CG @ N= \sum_{k=1}^N r_t(P^{\prime}(k)).
\] 

Discounted cumulative gain at $N$. Модификация позволяет учесть порядок элементов в топе.
\[
D C G @ N=\sum_{k=1}^N \frac{2^{r_t(P^{\prime}(k))}-1}{\log _2(k+1)}.
\]
В данной метрике чем более релевантен документ, тем больше числитель. Знаменатель зависит от позиции документа, он штрафует за позицию документа в списке. Если документ очень релевантен, но занимает низкую позицию, то штраф будет большим, иначе маленьким. метрика достигает максимума, если все релевантные документы находятся в топе поисковой выдачи.

Normalized discounted cumulative gain at $N$. Призвана нормализовать результаты предыдущей метрики.
\[
тD C G @ N=\frac{D C G @ N}{maxD C G @ N},
\]
где $maxD C G @ N$ --- значение метрик при идеальном ранжировании.

\section{Сравнение алгоритмов}

Сравнение алгоритмов производилось по наборам данных таких коллекций как: AOL, LETOR 2.0, LETOR 3.0, LETOR 4.0, MSLR, WCL2R, Yahoo! Learning to Rank Challenge, Yandex Internet Mathematics 2009 contest. В самих датасетах содержатся не документы, а векторы их признаков. Таким образом, любая разница в производительности ранжирования обусловлена алгоритмом ранжирования, а не используемыми функциями.

Для оценки общей эффективности обучения методам ранжирования используется показатель <<выигрышное число>>~\cite{cmp}. Оно определяется как количество алгоритмов, которое алгоритм может превзойти на наборе датасетов, или более формально
\[
\mathrm{WN}_i(M)=\sum_{j=1}^n \sum_{k=1}^m I_{\{M_i(j)>M_k(j)\}},
\]
где $j$ --- номер набора данных, $n$ --- кол-во наборов данных, $i$, $k$ --- индексы алгоритмов, $M_i(j)$ --- производительность $i$-го алгоритма на $j$-ом наборе данных и $I_{\{M_i(j)>M_k(j)\}}$ --- индикаторная функция, такая что
\[
I_{\{M_i(j)>M_k(j)\}}= \begin{cases}1 & \text { если оба определены и } M_i(j)>M_k(j) \\ 0 & \text { иначе }\end{cases}.
\]

Будем использовать нормализованное <<выигрышное число>>, для удобства интерпретации результатов, определённое как:
\[
NWN_i(M)=\frac{WN_i(M)}{IWN_i(M)},
\]
где $IWN_i(M)$ --- идеальное <<выигрышное число>>, то есть теоретически наибольшее число, которое было
бы у алгоритма в случае, если бы он был наиболее точным. Определяется как:
\[
\mathrm{IWN}_i(M)=\sum_{j=1}^n \sum_{k=1}^m D_{\{M_i(j)>M_k(j)\}},
\]
где индикаторная функция имеет значение
\[
D_{\{M_i(j)>M_k(j)\}}= \begin{cases}1 & \text { если оба определены } \\ 0 & \text { иначе }\end{cases}.
\]

Согласно~\cite{cmp} результаты замеров приведены в таблице~\ref{tbl:measure}.

\begin{table}[h]
	\begin{center}
		\begin{threeparttable}
			\captionsetup{justification=raggedright,singlelinecheck=off}
			\caption{Результаты замеров производительности методов обучения ранжированию}
			\label{tbl:measure}
			\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
				\hline
				 & \multicolumn{2}{c|}{NDCG@3} & \multicolumn{2}{c|}{NDCG@5} & \multicolumn{2}{c|}{NDCG@10} & \multicolumn{2}{c|}{MAP} \\\hline
				Метод & NWN  & к.д. & NWN  & к.д & NWN  & к.д & NWN  & к.д. \\\hline
				Linear Regression & 0.0754 & 9 & 0.1099& 9& 0.0829& 8& 0.0650& 8 \\\hline
				Ranking SVM &  0.3014 & 12& 0.3613& 11& 0.4496& 17& 0.3400& 13 \\\hline
				LambdaRank &  0.2000 &1 &0.2000 &1 &0.5714& 2 &-& - \\\hline
				ListNet &  0.4480 &12 &0.4911 &12 &0.5982 &12 &0.4504 &12 \\\hline
			\end{tabular}
		\end{threeparttable}
	\end{center}
\end{table}

\section{Вывод}

Лучше всех себя показал алгоритм ListNet (списочный подход). На основе данной выборки методов, сложно сказать что списочный подход даёт лучшие показатели метрик чем остальные, так как она довольно мала, однако в большинстве случаев так и есть.